# Local-RAG-Agent
# ğŸ§  Local AI Agent: O Meu "Copilot" Privativo

## ğŸ“Œ Sobre o Projeto
Este projeto Ã© um agente de InteligÃªncia Artificial desenvolvido em Python que permite conversar com documentos locais (PDF, TXT) de forma 100% privada. Diferente do Copilot ou ChatGPT, nenhum dado sai da mÃ¡quina, e nÃ£o hÃ¡ custos de API, pois utiliza modelos open-source rodando localmente.

## ğŸ› ï¸ Tecnologias Utilizadas
- **Linguagem:** Python 3.10+
- **OrquestraÃ§Ã£o:** LangChain (para criar a lÃ³gica do agente)
- **Modelo de IA:** Llama 3 (via Ollama)
- **Banco de Dados de Vetores:** FAISS ou ChromaDB
- **Interface:** Streamlit (Web UI)

## ğŸš€ Funcionalidades
- [x] ExtraÃ§Ã£o de texto de arquivos PDF.
- [x] FragmentaÃ§Ã£o inteligente de texto (Chunking) para alta performance.
- [x] Busca semÃ¢ntica por similaridade (o agente entende o contexto).
- [ ] Upload de documentos via interface Web.
- [ ] Chat interativo com histÃ³rico de conversa.
- [x] ExecuÃ§Ã£o 100% offline e gratuita.

---

## ğŸ’» Como Instalar e Rodar

1. Configurar o Ambiente Virtual
# Criar o ambiente
python -m venv venv

# Ativar o ambiente (Windows)
source venv/Scripts/activate.

2. Instalar DependÃªncias
Bash
pip install langchain-community langchain-ollama langchain-huggingface pypdf faiss-cpu sentence-transformers

3. Baixar Modelos no Ollama
Bash
ollama pull llama3
ollama pull phi3

4. Executar o Agente
Bash
python agente_pro.py
---
## ğŸš§ Status do Projeto
Em desenvolvimento ğŸ› ï¸ PrÃ³ximo passo: ImplementaÃ§Ã£o da interface grÃ¡fica com Streamlit.
Desenvolvido por Vitoria
